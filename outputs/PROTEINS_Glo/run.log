+-----------------+-------------------+
|    Parameter    |       Value       |
+=================+===================+
| Batch size      | 128               |
+-----------------+-------------------+
| Dataset         | PROTEINS          |
+-----------------+-------------------+
| Dropout ratio   | 0.5               |
+-----------------+-------------------+
| Epochs          | 10000             |
+-----------------+-------------------+
| Exp name        | PROTEINS_Glo      |
+-----------------+-------------------+
| Gpu index       | 0                 |
+-----------------+-------------------+
| Hid             | 128               |
+-----------------+-------------------+
| Lr              | 0.0005            |
+-----------------+-------------------+
| Model           | SAGPooling_Global |
+-----------------+-------------------+
| Patience        | 40                |
+-----------------+-------------------+
| Pooling ratio   | 0.5               |
+-----------------+-------------------+
| Seed            | 16                |
+-----------------+-------------------+
| Test batch size | 1                 |
+-----------------+-------------------+
| Weight decay    | 0.0001            |
+-----------------+-------------------+
Using GPU: 0
SAGPooling_Global(
  (conv1): GCNConv(3, 128)
  (conv2): GCNConv(128, 128)
  (conv3): GCNConv(128, 128)
  (pool): SAGPooling(GCNConv, 384, ratio=0.5, multiplier=1.0)
  (lin1): Linear(in_features=768, out_features=128, bias=True)
  (lin2): Linear(in_features=128, out_features=64, bias=True)
  (classifier): Linear(in_features=64, out_features=2, bias=True)
)
Model Parameter: 140740
Using Adam

Epoch #000, Train_Loss: [0.6876, 0.6877, 0.6868, 0.6811, 0.6931, 0.6833, 0.6797]
Val_Loss: 0.683576, Val_Acc: 0.585586
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #001, Train_Loss: [0.6840, 0.6824, 0.6867, 0.6792, 0.6720, 0.6888, 0.6745]
Val_Loss: 0.678329, Val_Acc: 0.585586
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #002, Train_Loss: [0.6870, 0.6739, 0.6661, 0.6908, 0.6761, 0.6736, 0.6582]
Val_Loss: 0.673334, Val_Acc: 0.585586
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #003, Train_Loss: [0.6685, 0.6535, 0.6934, 0.6864, 0.6540, 0.6710, 0.6666]
Val_Loss: 0.667396, Val_Acc: 0.585586
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #004, Train_Loss: [0.6470, 0.6622, 0.6951, 0.6736, 0.6682, 0.6311, 0.6888]
Val_Loss: 0.662468, Val_Acc: 0.585586
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #005, Train_Loss: [0.6757, 0.6435, 0.6536, 0.6649, 0.6560, 0.7047, 0.6235]
Val_Loss: 0.655742, Val_Acc: 0.585586
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #006, Train_Loss: [0.6519, 0.6548, 0.6510, 0.6513, 0.6299, 0.6604, 0.6823]
Val_Loss: 0.644509, Val_Acc: 0.657658
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #007, Train_Loss: [0.6422, 0.6641, 0.6615, 0.6343, 0.6459, 0.6196, 0.6276]
Val_Loss: 0.620880, Val_Acc: 0.657658
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #008, Train_Loss: [0.5911, 0.6406, 0.6231, 0.6241, 0.6264, 0.6309, 0.6298]
Val_Loss: 0.587590, Val_Acc: 0.657658
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #009, Train_Loss: [0.6277, 0.5801, 0.6421, 0.5784, 0.6583, 0.5936, 0.6181]
Val_Loss: 0.578327, Val_Acc: 0.711712
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #010, Train_Loss: [0.5814, 0.5500, 0.5972, 0.6413, 0.6379, 0.6236, 0.6454]
Val_Loss: 0.572765, Val_Acc: 0.729730
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #011, Train_Loss: [0.6231, 0.5601, 0.6584, 0.6007, 0.5980, 0.6043, 0.5843]
Val_Loss: 0.558703, Val_Acc: 0.729730
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #012, Train_Loss: [0.5697, 0.4944, 0.7080, 0.5993, 0.5889, 0.6140, 0.5748]
Val_Loss: 0.539071, Val_Acc: 0.729730
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #013, Train_Loss: [0.5812, 0.5137, 0.5725, 0.5993, 0.5470, 0.6584, 0.6814]
Val_Loss: 0.550071, Val_Acc: 0.720721

Epoch #014, Train_Loss: [0.5732, 0.5843, 0.5402, 0.5899, 0.5969, 0.5958, 0.5861]
Val_Loss: 0.549250, Val_Acc: 0.738739

Epoch #015, Train_Loss: [0.5750, 0.5997, 0.5582, 0.5555, 0.6141, 0.5185, 0.5703]
Val_Loss: 0.528928, Val_Acc: 0.747748
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #016, Train_Loss: [0.5936, 0.5168, 0.5853, 0.5349, 0.6303, 0.5875, 0.6196]
Val_Loss: 0.527073, Val_Acc: 0.720721
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #017, Train_Loss: [0.6188, 0.5615, 0.5644, 0.6115, 0.5887, 0.5410, 0.5275]
Val_Loss: 0.541718, Val_Acc: 0.729730

Epoch #018, Train_Loss: [0.6026, 0.6579, 0.5703, 0.5348, 0.5782, 0.5469, 0.4943]
Val_Loss: 0.526984, Val_Acc: 0.747748
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #019, Train_Loss: [0.5698, 0.4975, 0.5784, 0.6752, 0.6043, 0.5143, 0.5743]
Val_Loss: 0.531562, Val_Acc: 0.720721

Epoch #020, Train_Loss: [0.5325, 0.5572, 0.5788, 0.5518, 0.5427, 0.5682, 0.6057]
Val_Loss: 0.528452, Val_Acc: 0.738739

Epoch #021, Train_Loss: [0.5589, 0.5431, 0.6213, 0.5216, 0.5280, 0.5517, 0.6198]
Val_Loss: 0.518981, Val_Acc: 0.738739
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #022, Train_Loss: [0.4760, 0.6427, 0.5109, 0.5288, 0.5852, 0.5722, 0.5969]
Val_Loss: 0.525534, Val_Acc: 0.738739

Epoch #023, Train_Loss: [0.6116, 0.5183, 0.5172, 0.5578, 0.5517, 0.5616, 0.5547]
Val_Loss: 0.526891, Val_Acc: 0.729730

Epoch #024, Train_Loss: [0.5924, 0.5988, 0.5071, 0.5508, 0.5077, 0.5780, 0.5529]
Val_Loss: 0.526910, Val_Acc: 0.738739

Epoch #025, Train_Loss: [0.5645, 0.5161, 0.5616, 0.5157, 0.5485, 0.5527, 0.6021]
Val_Loss: 0.515334, Val_Acc: 0.738739
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #026, Train_Loss: [0.6031, 0.5838, 0.5657, 0.5226, 0.5913, 0.5771, 0.4652]
Val_Loss: 0.523514, Val_Acc: 0.738739

Epoch #027, Train_Loss: [0.5499, 0.5139, 0.5636, 0.5446, 0.5990, 0.5285, 0.5502]
Val_Loss: 0.525828, Val_Acc: 0.738739

Epoch #028, Train_Loss: [0.5389, 0.5229, 0.5383, 0.5591, 0.5264, 0.5980, 0.5645]
Val_Loss: 0.520249, Val_Acc: 0.747748

Epoch #029, Train_Loss: [0.5553, 0.5460, 0.6151, 0.5758, 0.4754, 0.5353, 0.5295]
Val_Loss: 0.515508, Val_Acc: 0.765766

Epoch #030, Train_Loss: [0.5431, 0.4771, 0.5518, 0.5907, 0.5489, 0.5676, 0.5890]
Val_Loss: 0.520413, Val_Acc: 0.747748

Epoch #031, Train_Loss: [0.5856, 0.5796, 0.5307, 0.6176, 0.5269, 0.4805, 0.5463]
Val_Loss: 0.522434, Val_Acc: 0.756757

Epoch #032, Train_Loss: [0.5210, 0.5701, 0.5837, 0.5033, 0.5537, 0.5576, 0.5105]
Val_Loss: 0.520718, Val_Acc: 0.756757

Epoch #033, Train_Loss: [0.5264, 0.4861, 0.6411, 0.5899, 0.5771, 0.4755, 0.5726]
Val_Loss: 0.520276, Val_Acc: 0.756757

Epoch #034, Train_Loss: [0.5388, 0.5131, 0.5584, 0.4803, 0.6336, 0.5321, 0.5156]
Val_Loss: 0.515661, Val_Acc: 0.738739

Epoch #035, Train_Loss: [0.5428, 0.5858, 0.5444, 0.5034, 0.5087, 0.5357, 0.5891]
Val_Loss: 0.516541, Val_Acc: 0.765766

Epoch #036, Train_Loss: [0.5447, 0.5033, 0.5507, 0.5855, 0.4820, 0.5907, 0.5758]
Val_Loss: 0.519107, Val_Acc: 0.783784

Epoch #037, Train_Loss: [0.5427, 0.5302, 0.5229, 0.5058, 0.5984, 0.5304, 0.5622]
Val_Loss: 0.517322, Val_Acc: 0.747748

Epoch #038, Train_Loss: [0.5610, 0.4440, 0.5449, 0.6445, 0.4822, 0.5337, 0.5789]
Val_Loss: 0.515197, Val_Acc: 0.765766
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #039, Train_Loss: [0.5078, 0.5574, 0.6016, 0.4944, 0.5714, 0.5383, 0.5961]
Val_Loss: 0.515598, Val_Acc: 0.783784

Epoch #040, Train_Loss: [0.5447, 0.5951, 0.5824, 0.4995, 0.5097, 0.5718, 0.5486]
Val_Loss: 0.522914, Val_Acc: 0.738739

Epoch #041, Train_Loss: [0.5243, 0.5689, 0.5547, 0.4996, 0.4818, 0.5381, 0.6301]
Val_Loss: 0.518767, Val_Acc: 0.756757

Epoch #042, Train_Loss: [0.5355, 0.4669, 0.5583, 0.5587, 0.5299, 0.5612, 0.5299]
Val_Loss: 0.516660, Val_Acc: 0.738739

Epoch #043, Train_Loss: [0.5309, 0.6007, 0.5321, 0.4821, 0.5422, 0.5710, 0.5408]
Val_Loss: 0.518192, Val_Acc: 0.756757

Epoch #044, Train_Loss: [0.5512, 0.5434, 0.5612, 0.5206, 0.5151, 0.5491, 0.5394]
Val_Loss: 0.519267, Val_Acc: 0.738739

Epoch #045, Train_Loss: [0.5014, 0.6027, 0.4638, 0.5520, 0.5159, 0.5905, 0.5382]
Val_Loss: 0.513712, Val_Acc: 0.747748
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #046, Train_Loss: [0.5440, 0.5599, 0.5495, 0.4774, 0.5323, 0.5575, 0.5384]
Val_Loss: 0.511618, Val_Acc: 0.756757
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #047, Train_Loss: [0.5073, 0.5525, 0.5600, 0.5109, 0.5266, 0.5675, 0.5621]
Val_Loss: 0.517270, Val_Acc: 0.738739

Epoch #048, Train_Loss: [0.5627, 0.5655, 0.4891, 0.5503, 0.5652, 0.5136, 0.5072]
Val_Loss: 0.516645, Val_Acc: 0.738739

Epoch #049, Train_Loss: [0.4774, 0.5415, 0.5600, 0.5847, 0.6105, 0.4902, 0.5042]
Val_Loss: 0.511695, Val_Acc: 0.765766

Epoch #050, Train_Loss: [0.5198, 0.5233, 0.5566, 0.5553, 0.5094, 0.5984, 0.5383]
Val_Loss: 0.516850, Val_Acc: 0.756757

Epoch #051, Train_Loss: [0.5865, 0.4668, 0.5061, 0.4820, 0.5474, 0.6009, 0.5397]
Val_Loss: 0.519879, Val_Acc: 0.738739

Epoch #052, Train_Loss: [0.6100, 0.5041, 0.5264, 0.6050, 0.4880, 0.4766, 0.5061]
Val_Loss: 0.515549, Val_Acc: 0.774775

Epoch #053, Train_Loss: [0.5494, 0.5269, 0.5533, 0.4961, 0.5315, 0.5987, 0.5020]
Val_Loss: 0.515141, Val_Acc: 0.774775

Epoch #054, Train_Loss: [0.5882, 0.5343, 0.5397, 0.5728, 0.5715, 0.4937, 0.4651]
Val_Loss: 0.518286, Val_Acc: 0.765766

Epoch #055, Train_Loss: [0.5305, 0.5587, 0.4917, 0.5034, 0.5349, 0.5516, 0.5812]
Val_Loss: 0.511033, Val_Acc: 0.765766
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #056, Train_Loss: [0.5540, 0.6324, 0.5262, 0.4838, 0.5070, 0.5537, 0.4966]
Val_Loss: 0.512815, Val_Acc: 0.729730

Epoch #057, Train_Loss: [0.5223, 0.4805, 0.4749, 0.5583, 0.5778, 0.5093, 0.5999]
Val_Loss: 0.519129, Val_Acc: 0.756757

Epoch #058, Train_Loss: [0.4854, 0.5078, 0.5641, 0.5962, 0.5266, 0.5191, 0.5251]
Val_Loss: 0.514384, Val_Acc: 0.747748

Epoch #059, Train_Loss: [0.5168, 0.6346, 0.5351, 0.5333, 0.5327, 0.5084, 0.4971]
Val_Loss: 0.515437, Val_Acc: 0.756757

Epoch #060, Train_Loss: [0.5760, 0.4991, 0.4889, 0.5280, 0.5322, 0.5029, 0.6100]
Val_Loss: 0.512039, Val_Acc: 0.765766

Epoch #061, Train_Loss: [0.6124, 0.4840, 0.5206, 0.5393, 0.5447, 0.5195, 0.4944]
Val_Loss: 0.515278, Val_Acc: 0.729730

Epoch #062, Train_Loss: [0.5324, 0.4774, 0.5203, 0.5762, 0.5490, 0.5531, 0.4710]
Val_Loss: 0.510902, Val_Acc: 0.774775
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #063, Train_Loss: [0.6053, 0.4668, 0.5061, 0.5378, 0.5168, 0.4743, 0.5707]
Val_Loss: 0.514122, Val_Acc: 0.774775

Epoch #064, Train_Loss: [0.5712, 0.4564, 0.5359, 0.5105, 0.5274, 0.5403, 0.5476]
Val_Loss: 0.509173, Val_Acc: 0.729730
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #065, Train_Loss: [0.4891, 0.5795, 0.5191, 0.5143, 0.5711, 0.5332, 0.4832]
Val_Loss: 0.512131, Val_Acc: 0.765766

Epoch #066, Train_Loss: [0.5500, 0.4673, 0.5611, 0.4637, 0.5980, 0.5303, 0.5281]
Val_Loss: 0.510189, Val_Acc: 0.756757

Epoch #067, Train_Loss: [0.5388, 0.5301, 0.5013, 0.5296, 0.5169, 0.5028, 0.5377]
Val_Loss: 0.512754, Val_Acc: 0.756757

Epoch #068, Train_Loss: [0.5146, 0.5377, 0.5278, 0.5448, 0.5906, 0.4966, 0.4627]
Val_Loss: 0.514231, Val_Acc: 0.765766

Epoch #069, Train_Loss: [0.4955, 0.5831, 0.5946, 0.4841, 0.5382, 0.4785, 0.4862]
Val_Loss: 0.507923, Val_Acc: 0.765766
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #070, Train_Loss: [0.5558, 0.5062, 0.4913, 0.4791, 0.5543, 0.5198, 0.5480]
Val_Loss: 0.506020, Val_Acc: 0.747748
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #071, Train_Loss: [0.5290, 0.4887, 0.5543, 0.5295, 0.5279, 0.4710, 0.5695]
Val_Loss: 0.511486, Val_Acc: 0.756757

Epoch #072, Train_Loss: [0.4541, 0.5517, 0.5747, 0.5375, 0.5226, 0.5313, 0.5066]
Val_Loss: 0.509975, Val_Acc: 0.756757

Epoch #073, Train_Loss: [0.5361, 0.5056, 0.5569, 0.4695, 0.5424, 0.5627, 0.5200]
Val_Loss: 0.509951, Val_Acc: 0.765766

Epoch #074, Train_Loss: [0.5299, 0.5447, 0.5589, 0.4763, 0.5669, 0.5221, 0.4778]
Val_Loss: 0.513951, Val_Acc: 0.738739

Epoch #075, Train_Loss: [0.5590, 0.5336, 0.4846, 0.5009, 0.5310, 0.4882, 0.5766]
Val_Loss: 0.514728, Val_Acc: 0.720721

Epoch #076, Train_Loss: [0.5280, 0.4590, 0.5535, 0.5640, 0.4891, 0.4889, 0.5180]
Val_Loss: 0.514286, Val_Acc: 0.756757

Epoch #077, Train_Loss: [0.4996, 0.5355, 0.5492, 0.5249, 0.5463, 0.4844, 0.4740]
Val_Loss: 0.509891, Val_Acc: 0.747748

Epoch #078, Train_Loss: [0.5353, 0.5455, 0.5115, 0.5379, 0.4936, 0.5286, 0.5271]
Val_Loss: 0.524511, Val_Acc: 0.747748

Epoch #079, Train_Loss: [0.5272, 0.5415, 0.4853, 0.5152, 0.5904, 0.5124, 0.4770]
Val_Loss: 0.509612, Val_Acc: 0.747748

Epoch #080, Train_Loss: [0.5170, 0.5036, 0.5235, 0.5668, 0.4844, 0.5366, 0.5662]
Val_Loss: 0.506817, Val_Acc: 0.765766

Epoch #081, Train_Loss: [0.5073, 0.4891, 0.4970, 0.5705, 0.5178, 0.6296, 0.4492]
Val_Loss: 0.514425, Val_Acc: 0.738739

Epoch #082, Train_Loss: [0.5514, 0.5371, 0.5537, 0.5107, 0.5231, 0.5356, 0.4172]
Val_Loss: 0.518816, Val_Acc: 0.756757

Epoch #083, Train_Loss: [0.5561, 0.5211, 0.5186, 0.5439, 0.4857, 0.4445, 0.5587]
Val_Loss: 0.515826, Val_Acc: 0.729730

Epoch #084, Train_Loss: [0.5344, 0.6244, 0.4462, 0.5167, 0.4939, 0.5123, 0.5269]
Val_Loss: 0.504135, Val_Acc: 0.756757
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #085, Train_Loss: [0.4655, 0.5374, 0.5146, 0.5875, 0.4725, 0.5544, 0.4940]
Val_Loss: 0.506871, Val_Acc: 0.765766

Epoch #086, Train_Loss: [0.4386, 0.4718, 0.5322, 0.4771, 0.5467, 0.6514, 0.5512]
Val_Loss: 0.507091, Val_Acc: 0.783784

Epoch #087, Train_Loss: [0.4958, 0.4610, 0.5201, 0.5184, 0.5001, 0.5734, 0.4997]
Val_Loss: 0.511654, Val_Acc: 0.747748

Epoch #088, Train_Loss: [0.4764, 0.4892, 0.4915, 0.4838, 0.5470, 0.4741, 0.6328]
Val_Loss: 0.507465, Val_Acc: 0.756757

Epoch #089, Train_Loss: [0.5387, 0.4708, 0.5444, 0.5587, 0.4954, 0.4887, 0.5128]
Val_Loss: 0.503478, Val_Acc: 0.783784
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #090, Train_Loss: [0.4692, 0.6081, 0.5935, 0.5005, 0.4842, 0.4673, 0.5314]
Val_Loss: 0.506129, Val_Acc: 0.783784

Epoch #091, Train_Loss: [0.4886, 0.4988, 0.5319, 0.5655, 0.4866, 0.5285, 0.4672]
Val_Loss: 0.499916, Val_Acc: 0.756757
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #092, Train_Loss: [0.5971, 0.4913, 0.5316, 0.4278, 0.4759, 0.5860, 0.4716]
Val_Loss: 0.504827, Val_Acc: 0.756757

Epoch #093, Train_Loss: [0.5874, 0.5677, 0.4819, 0.4543, 0.5044, 0.4670, 0.4904]
Val_Loss: 0.506704, Val_Acc: 0.765766

Epoch #094, Train_Loss: [0.5659, 0.6194, 0.4934, 0.5046, 0.5063, 0.5088, 0.4559]
Val_Loss: 0.518794, Val_Acc: 0.765766

Epoch #095, Train_Loss: [0.5624, 0.4575, 0.4363, 0.5230, 0.5266, 0.5539, 0.5585]
Val_Loss: 0.518249, Val_Acc: 0.738739

Epoch #096, Train_Loss: [0.5636, 0.4920, 0.5039, 0.5419, 0.6030, 0.4194, 0.4807]
Val_Loss: 0.507441, Val_Acc: 0.765766

Epoch #097, Train_Loss: [0.5416, 0.5483, 0.4737, 0.4964, 0.5451, 0.5493, 0.4844]
Val_Loss: 0.516865, Val_Acc: 0.756757

Epoch #098, Train_Loss: [0.4966, 0.5579, 0.5105, 0.5469, 0.4786, 0.5266, 0.4669]
Val_Loss: 0.509237, Val_Acc: 0.765766

Epoch #099, Train_Loss: [0.5067, 0.5293, 0.5049, 0.5055, 0.5273, 0.4895, 0.5253]
Val_Loss: 0.515254, Val_Acc: 0.765766

Epoch #100, Train_Loss: [0.5250, 0.5162, 0.5734, 0.4516, 0.5703, 0.4616, 0.4651]
Val_Loss: 0.507915, Val_Acc: 0.774775

Epoch #101, Train_Loss: [0.5243, 0.5013, 0.5094, 0.4530, 0.6139, 0.4986, 0.4717]
Val_Loss: 0.501688, Val_Acc: 0.774775

Epoch #102, Train_Loss: [0.4815, 0.5873, 0.4471, 0.4621, 0.4786, 0.4985, 0.5894]
Val_Loss: 0.500328, Val_Acc: 0.783784

Epoch #103, Train_Loss: [0.6107, 0.5099, 0.5479, 0.4784, 0.5087, 0.4800, 0.4522]
Val_Loss: 0.499595, Val_Acc: 0.783784
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #104, Train_Loss: [0.4626, 0.5797, 0.5603, 0.4827, 0.5280, 0.4635, 0.5369]
Val_Loss: 0.501578, Val_Acc: 0.765766

Epoch #105, Train_Loss: [0.4854, 0.5326, 0.5078, 0.5378, 0.4529, 0.5396, 0.5146]
Val_Loss: 0.499874, Val_Acc: 0.756757

Epoch #106, Train_Loss: [0.5358, 0.4735, 0.4755, 0.5603, 0.4550, 0.5816, 0.5151]
Val_Loss: 0.498349, Val_Acc: 0.756757
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #107, Train_Loss: [0.5506, 0.4694, 0.4674, 0.5038, 0.4842, 0.5805, 0.4461]
Val_Loss: 0.499510, Val_Acc: 0.774775

Epoch #108, Train_Loss: [0.5557, 0.4996, 0.4836, 0.5011, 0.4750, 0.4502, 0.5749]
Val_Loss: 0.492947, Val_Acc: 0.783784
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #109, Train_Loss: [0.5602, 0.5313, 0.5007, 0.4386, 0.5048, 0.5263, 0.4716]
Val_Loss: 0.495941, Val_Acc: 0.774775

Epoch #110, Train_Loss: [0.5297, 0.4984, 0.4437, 0.5465, 0.5093, 0.5044, 0.4910]
Val_Loss: 0.497006, Val_Acc: 0.774775

Epoch #111, Train_Loss: [0.5492, 0.4972, 0.4388, 0.5318, 0.4347, 0.6136, 0.5428]
Val_Loss: 0.510392, Val_Acc: 0.774775

Epoch #112, Train_Loss: [0.4903, 0.4725, 0.5212, 0.5498, 0.5226, 0.5152, 0.5201]
Val_Loss: 0.505128, Val_Acc: 0.765766

Epoch #113, Train_Loss: [0.4956, 0.5380, 0.5272, 0.5223, 0.5607, 0.4582, 0.4838]
Val_Loss: 0.508387, Val_Acc: 0.783784

Epoch #114, Train_Loss: [0.5219, 0.5305, 0.4526, 0.4871, 0.5480, 0.5334, 0.4589]
Val_Loss: 0.497231, Val_Acc: 0.765766

Epoch #115, Train_Loss: [0.4916, 0.5255, 0.4528, 0.5300, 0.5647, 0.4732, 0.4873]
Val_Loss: 0.498072, Val_Acc: 0.774775

Epoch #116, Train_Loss: [0.5829, 0.4788, 0.6036, 0.4114, 0.4926, 0.4836, 0.5170]
Val_Loss: 0.506447, Val_Acc: 0.765766

Epoch #117, Train_Loss: [0.4892, 0.5263, 0.4324, 0.5601, 0.4319, 0.4885, 0.6444]
Val_Loss: 0.497394, Val_Acc: 0.774775

Epoch #118, Train_Loss: [0.4303, 0.4326, 0.5108, 0.5160, 0.5702, 0.5485, 0.5636]
Val_Loss: 0.513313, Val_Acc: 0.765766

Epoch #119, Train_Loss: [0.5136, 0.5882, 0.4803, 0.4802, 0.4939, 0.5088, 0.5154]
Val_Loss: 0.517799, Val_Acc: 0.765766

Epoch #120, Train_Loss: [0.4676, 0.4820, 0.4955, 0.5109, 0.5378, 0.4767, 0.5576]
Val_Loss: 0.512373, Val_Acc: 0.774775

Epoch #121, Train_Loss: [0.5269, 0.5933, 0.4470, 0.5091, 0.5073, 0.4692, 0.4891]
Val_Loss: 0.507568, Val_Acc: 0.765766

Epoch #122, Train_Loss: [0.4839, 0.5187, 0.4646, 0.5711, 0.5482, 0.4610, 0.4942]
Val_Loss: 0.491751, Val_Acc: 0.774775
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********

Epoch #123, Train_Loss: [0.5225, 0.5015, 0.4964, 0.4634, 0.4863, 0.5206, 0.5148]
Val_Loss: 0.514787, Val_Acc: 0.765766

Epoch #124, Train_Loss: [0.4628, 0.5459, 0.4628, 0.5064, 0.5052, 0.5453, 0.5383]
Val_Loss: 0.501671, Val_Acc: 0.783784

Epoch #125, Train_Loss: [0.4484, 0.5764, 0.5129, 0.4940, 0.5080, 0.5323, 0.4602]
Val_Loss: 0.501011, Val_Acc: 0.774775

Epoch #126, Train_Loss: [0.5211, 0.4630, 0.4545, 0.4976, 0.5065, 0.5871, 0.5619]
Val_Loss: 0.506727, Val_Acc: 0.756757

Epoch #127, Train_Loss: [0.5033, 0.5106, 0.4402, 0.4400, 0.5099, 0.5151, 0.5910]
Val_Loss: 0.500506, Val_Acc: 0.765766

Epoch #128, Train_Loss: [0.5275, 0.5630, 0.4675, 0.4879, 0.4789, 0.4994, 0.5149]
Val_Loss: 0.525765, Val_Acc: 0.756757

Epoch #129, Train_Loss: [0.5547, 0.5405, 0.4992, 0.5287, 0.4996, 0.4561, 0.4396]
Val_Loss: 0.506423, Val_Acc: 0.765766

Epoch #130, Train_Loss: [0.5179, 0.4581, 0.5578, 0.4889, 0.5206, 0.5313, 0.4603]
Val_Loss: 0.501049, Val_Acc: 0.774775

Epoch #131, Train_Loss: [0.4811, 0.4772, 0.4689, 0.5333, 0.5946, 0.5608, 0.4954]
Val_Loss: 0.525253, Val_Acc: 0.756757

Epoch #132, Train_Loss: [0.4610, 0.5257, 0.4776, 0.5161, 0.4982, 0.4904, 0.5315]
Val_Loss: 0.523466, Val_Acc: 0.756757

Epoch #133, Train_Loss: [0.4103, 0.4989, 0.5844, 0.5660, 0.4971, 0.4733, 0.5191]
Val_Loss: 0.514155, Val_Acc: 0.765766

Epoch #134, Train_Loss: [0.4885, 0.5079, 0.5633, 0.5260, 0.4431, 0.5286, 0.4886]
Val_Loss: 0.511500, Val_Acc: 0.783784

Epoch #135, Train_Loss: [0.4664, 0.5102, 0.4818, 0.5492, 0.5077, 0.5173, 0.4561]
Val_Loss: 0.505023, Val_Acc: 0.738739

Epoch #136, Train_Loss: [0.4623, 0.4814, 0.4355, 0.5259, 0.4780, 0.5570, 0.5614]
Val_Loss: 0.520921, Val_Acc: 0.765766

Epoch #137, Train_Loss: [0.4263, 0.5353, 0.5148, 0.5342, 0.5034, 0.4607, 0.5429]
Val_Loss: 0.536321, Val_Acc: 0.774775

Epoch #138, Train_Loss: [0.4373, 0.4161, 0.5378, 0.4839, 0.6054, 0.4461, 0.5795]
Val_Loss: 0.521773, Val_Acc: 0.765766

Epoch #139, Train_Loss: [0.4876, 0.4910, 0.4420, 0.5411, 0.5653, 0.4905, 0.4862]
Val_Loss: 0.514224, Val_Acc: 0.765766

Epoch #140, Train_Loss: [0.5009, 0.4648, 0.4961, 0.5002, 0.4720, 0.5301, 0.5947]
Val_Loss: 0.522547, Val_Acc: 0.774775

Epoch #141, Train_Loss: [0.4746, 0.5765, 0.4461, 0.5320, 0.4222, 0.5436, 0.5066]
Val_Loss: 0.510309, Val_Acc: 0.783784

Epoch #142, Train_Loss: [0.5102, 0.4449, 0.5314, 0.4909, 0.4740, 0.5838, 0.4403]
Val_Loss: 0.521408, Val_Acc: 0.774775

Epoch #143, Train_Loss: [0.5257, 0.5334, 0.5178, 0.4625, 0.5292, 0.4473, 0.4752]
Val_Loss: 0.509839, Val_Acc: 0.783784

Epoch #144, Train_Loss: [0.4922, 0.5351, 0.5275, 0.4728, 0.4737, 0.4719, 0.5317]
Val_Loss: 0.511825, Val_Acc: 0.774775

Epoch #145, Train_Loss: [0.4679, 0.5438, 0.5000, 0.4715, 0.5327, 0.5334, 0.4212]
Val_Loss: 0.504496, Val_Acc: 0.756757

Epoch #146, Train_Loss: [0.4915, 0.4590, 0.5826, 0.5159, 0.4585, 0.5358, 0.5060]
Val_Loss: 0.516395, Val_Acc: 0.774775

Epoch #147, Train_Loss: [0.4365, 0.5492, 0.5287, 0.4673, 0.5151, 0.5262, 0.5089]
Val_Loss: 0.524206, Val_Acc: 0.747748

Epoch #148, Train_Loss: [0.5066, 0.5384, 0.4724, 0.5873, 0.4193, 0.4804, 0.4884]
Val_Loss: 0.512565, Val_Acc: 0.783784

Epoch #149, Train_Loss: [0.4964, 0.5591, 0.4382, 0.5140, 0.4339, 0.5124, 0.5727]
Val_Loss: 0.511307, Val_Acc: 0.774775

Epoch #150, Train_Loss: [0.5136, 0.5144, 0.4930, 0.5096, 0.4540, 0.4704, 0.5324]
Val_Loss: 0.539611, Val_Acc: 0.756757

Epoch #151, Train_Loss: [0.5049, 0.4955, 0.5036, 0.4782, 0.4792, 0.4686, 0.5388]
Val_Loss: 0.513290, Val_Acc: 0.774775

Epoch #152, Train_Loss: [0.5367, 0.5292, 0.5138, 0.4582, 0.4626, 0.4741, 0.4586]
Val_Loss: 0.499118, Val_Acc: 0.783784

Epoch #153, Train_Loss: [0.5243, 0.5094, 0.5447, 0.4839, 0.4835, 0.4533, 0.4768]
Val_Loss: 0.503650, Val_Acc: 0.783784

Epoch #154, Train_Loss: [0.5119, 0.4751, 0.4825, 0.4872, 0.5197, 0.5120, 0.4939]
Val_Loss: 0.526842, Val_Acc: 0.774775

Epoch #155, Train_Loss: [0.4736, 0.5541, 0.5325, 0.4874, 0.5155, 0.4543, 0.4859]
Val_Loss: 0.518091, Val_Acc: 0.765766

Epoch #156, Train_Loss: [0.5270, 0.5052, 0.5064, 0.4369, 0.5419, 0.4362, 0.5051]
Val_Loss: 0.506910, Val_Acc: 0.783784

Epoch #157, Train_Loss: [0.5313, 0.4979, 0.4035, 0.5470, 0.4377, 0.5049, 0.5465]
Val_Loss: 0.504201, Val_Acc: 0.774775

Epoch #158, Train_Loss: [0.4322, 0.5450, 0.4933, 0.5093, 0.5469, 0.4190, 0.5344]
Val_Loss: 0.525089, Val_Acc: 0.756757

Epoch #159, Train_Loss: [0.5077, 0.5064, 0.4946, 0.4749, 0.4991, 0.4890, 0.5106]
Val_Loss: 0.527376, Val_Acc: 0.774775

Epoch #160, Train_Loss: [0.4984, 0.5545, 0.4884, 0.5002, 0.4331, 0.4783, 0.5061]
Val_Loss: 0.512546, Val_Acc: 0.783784

Epoch #161, Train_Loss: [0.4624, 0.4525, 0.5208, 0.5411, 0.5184, 0.4288, 0.5457]
Val_Loss: 0.516610, Val_Acc: 0.774775

Epoch #162, Train_Loss: [0.4729, 0.5199, 0.4964, 0.4161, 0.4649, 0.5429, 0.4765]
Val_Loss: 0.528178, Val_Acc: 0.765766

Epoch #163, Train_Loss: [0.4519, 0.5228, 0.5227, 0.4819, 0.4918, 0.4511, 0.5168]
Val_Loss: 0.530743, Val_Acc: 0.765766

********** TEST START **********
Reload Best Model
The current best model is saved in: ******** outputs/PROTEINS_Glo/model.pth *********
TEST :: Test_Acc: 0.732143
